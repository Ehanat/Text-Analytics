{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e574222a-5616-4bce-ba2e-9ea527f85bd3",
   "metadata": {},
   "source": [
    "## Lab Assignment 2 [Text Analytics - CISB5123]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39fc02f-bb85-4cf7-bd11-25bdcad92414",
   "metadata": {},
   "source": [
    "### <span style='background :yellow' > Student Information (Group Members) </span>\n",
    "\n",
    "Member 1\n",
    "\n",
    "**Name     :** Zulfadhli Fakhri bin Johan\n",
    "\n",
    "**ID No    :** SW01081044\n",
    "\n",
    "**Section  :** 02\n",
    "\n",
    "=============================================================\n",
    "\n",
    "Member 2\n",
    "\n",
    "**Name     :** Errenbai Yeerhanati\n",
    "\n",
    "**ID No    :** SW01081538\n",
    "\n",
    "**Section  :** 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95630d17-1bb0-4dd1-980f-5de5e974e10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\zeef\\anaconda3\\lib\\site-packages (0.18.0.post0)\n",
      "Requirement already satisfied: nltk>=3.8 in c:\\users\\zeef\\anaconda3\\lib\\site-packages (from textblob) (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\zeef\\anaconda3\\lib\\site-packages (from nltk>=3.8->textblob) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\zeef\\anaconda3\\lib\\site-packages (from nltk>=3.8->textblob) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\zeef\\anaconda3\\lib\\site-packages (from nltk>=3.8->textblob) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\zeef\\anaconda3\\lib\\site-packages (from nltk>=3.8->textblob) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\zeef\\anaconda3\\lib\\site-packages (from click->nltk>=3.8->textblob) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10c3566b-6928-4f3a-bc2f-8dd3d37866f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vaderSentiment in c:\\users\\zeef\\anaconda3\\lib\\site-packages (3.3.2)\n",
      "Requirement already satisfied: requests in c:\\users\\zeef\\anaconda3\\lib\\site-packages (from vaderSentiment) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\zeef\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\zeef\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\zeef\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\zeef\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a96b2a3e-1039-4728-8a4c-81a713fe38d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c91e477-ac8c-4c5c-8f27-d9ad08c52870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"Reviews.csv\").head(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d85d788e-4932-42ff-b81d-916a4ecedb55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Value Counts:\n",
      "Score\n",
      "5    12571\n",
      "4     2836\n",
      "1     1824\n",
      "3     1649\n",
      "2     1120\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display count of each score\n",
    "print(\"Score Value Counts:\")\n",
    "print(df['Score'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c029e6d-0cc1-4018-8098-e174105e6d87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display first 5 rows BEFORE modifying the score\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71ba2dd8-2a3c-4ab3-8d5f-6a2e4c8fcb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the values of the Score column\n",
    "df['Score'] = df['Score'].map({1: 0, 2: 0, 3: 1, 4: 2, 5: 2})\n",
    "\n",
    "# Score 1 and 2 = negative (0)\n",
    "# Score 3 = neutral (1)\n",
    "# Score 4 and 5 = positive (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d2c09dc-889f-4a28-8df1-0bdeaff59011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Value Counts (Modified):\n",
      "Score\n",
      "2    15407\n",
      "0     2944\n",
      "1     1649\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display count of updated score\n",
    "print(\"Score Value Counts (Modified):\")\n",
    "print(df['Score'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de7c751e-df3e-4d34-885d-07e7e31c4546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      2  1303862400   \n",
       "1                     0                       0      0  1346976000   \n",
       "2                     1                       1      2  1219017600   \n",
       "3                     3                       3      0  1307923200   \n",
       "4                     0                       0      2  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display first 5 rows AFTER modifying the score\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bcd5d6d-5ab2-4a9b-9b80-dd5e8e5f8df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "stop_words = stopwords.words('english')\n",
    "more_stopwords = ['u', 'im', 'ive', 'would', 'havent', 'dont', 'id', 'etc', 'wasnt', 'didnt', 'theyll', 'oh', 'cant',\n",
    "                 'doesnt', 'youre', 'youd', 'youll', 'theyre', 'whats', 'thats', 'isnt', 'wont', 'werent', 'weve',\n",
    "                  'shouldve', 'couldnt', 'could']\n",
    "stop_words = stop_words + more_stopwords\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7000ab7-37a8-4203-9b6d-76cbe30083a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'u',\n",
       " 'im',\n",
       " 'ive',\n",
       " 'would',\n",
       " 'havent',\n",
       " 'dont',\n",
       " 'id',\n",
       " 'etc',\n",
       " 'wasnt',\n",
       " 'didnt',\n",
       " 'theyll',\n",
       " 'oh',\n",
       " 'cant',\n",
       " 'doesnt',\n",
       " 'youre',\n",
       " 'youd',\n",
       " 'youll',\n",
       " 'theyre',\n",
       " 'whats',\n",
       " 'thats',\n",
       " 'isnt',\n",
       " 'wont',\n",
       " 'werent',\n",
       " 'weve',\n",
       " 'shouldve',\n",
       " 'couldnt',\n",
       " 'could']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a98d8c7-aa83-4c08-96ed-0b56bf7d6f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()  # Convert text to lowercase\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)  # Remove text within square brackets\n",
    "    text = re.sub(r'http\\S+\\s*\\S+', '', text)  # Remove URLs starting with http\n",
    "    text = re.sub(r'www\\.\\S+', '', text)  # Remove URLs starting with www\n",
    "    text = re.sub(r'<.*?>', '', text)  # Remove HTML tags\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = re.sub(r'\\b\\w*\\d\\w*\\b', '', text)  # Remove words containing numbers\n",
    "    tokens = word_tokenize(text) # Tokenize\n",
    "    text = ' '.join(word for word in tokens if word not in stop_words) # Remove stopwords\n",
    "    text = ' '.join(lemmatizer.lemmatize(word) for word in text.split(' ')) # Lemmatization\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b8e08a5-7950-44ab-a383-eb12e75abc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text'] = df['Text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57d5a3a7-98df-49ff-96cc-f19d961bf9fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>bought several vitality canned dog food produc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>product arrived labeled jumbo salted peanutsth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>confection around century light pillowy citrus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>looking secret ingredient robitussin believe f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>great taffy great price wide assortment yummy ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      2  1303862400   \n",
       "1                     0                       0      0  1346976000   \n",
       "2                     1                       1      2  1219017600   \n",
       "3                     3                       3      0  1307923200   \n",
       "4                     0                       0      2  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \\\n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...   \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...   \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...   \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...   \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  bought several vitality canned dog food produc...  \n",
       "1  product arrived labeled jumbo salted peanutsth...  \n",
       "2  confection around century light pillowy citrus...  \n",
       "3  looking secret ingredient robitussin believe f...  \n",
       "4  great taffy great price wide assortment yummy ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display first 5 rows AFTER preprocessed Text into clean_text\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb7de42f-1979-493f-ae1a-86ee9ff34801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Text</th>\n",
       "      <th>Cleaned Text</th>\n",
       "      <th>Actual Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>bought several vitality canned dog food produc...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>product arrived labeled jumbo salted peanutsth...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>confection around century light pillowy citrus...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>looking secret ingredient robitussin believe f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>great taffy great price wide assortment yummy ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Actual Text  \\\n",
       "0  I have bought several of the Vitality canned d...   \n",
       "1  Product arrived labeled as Jumbo Salted Peanut...   \n",
       "2  This is a confection that has been around a fe...   \n",
       "3  If you are looking for the secret ingredient i...   \n",
       "4  Great taffy at a great price.  There was a wid...   \n",
       "\n",
       "                                        Cleaned Text  Actual Label  \n",
       "0  bought several vitality canned dog food produc...             2  \n",
       "1  product arrived labeled jumbo salted peanutsth...             0  \n",
       "2  confection around century light pillowy citrus...             2  \n",
       "3  looking secret ingredient robitussin believe f...             0  \n",
       "4  great taffy great price wide assortment yummy ...             2  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save Text and cleaned_text into a new CSV file\n",
    "df_text_clean = pd.DataFrame(data={'Actual Text': df['Text'], 'Cleaned Text': df['clean_text'], 'Actual Label': df['Score']})\n",
    "df_text_clean.to_csv('Preprocessed_Text.csv', index=False)\n",
    "df_text_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28974969-5daa-48cd-a570-96cea29db566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X = tfidf_vectorizer.fit_transform(df['clean_text'])\n",
    "y = df['Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f671fd4-fcda-47d9-9225-493ab6736a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Selection\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4adab6b-3edd-4029-805b-ec10bc53dd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomial Naive Bayes model\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "nb_pred = nb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "def3d482-1fb9-4fc5-965b-c6dd60816590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine (SVM) model\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train, y_train)\n",
    "svm_pred = svm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4194619-d617-43bd-a821-4bc0f0567802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.84825\n",
      "Naive Bayes Accuracy: 0.7705\n",
      "\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.58      0.66       589\n",
      "     neutral       0.61      0.08      0.14       330\n",
      "    positive       0.86      0.98      0.92      3081\n",
      "\n",
      "    accuracy                           0.85      4000\n",
      "   macro avg       0.75      0.55      0.57      4000\n",
      "weighted avg       0.83      0.85      0.82      4000\n",
      "\n",
      "\n",
      "Naive Bayes Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.00      0.01       589\n",
      "     neutral       1.00      0.00      0.00       330\n",
      "    positive       0.77      1.00      0.87      3081\n",
      "\n",
      "    accuracy                           0.77      4000\n",
      "   macro avg       0.81      0.33      0.29      4000\n",
      "weighted avg       0.77      0.77      0.67      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation\n",
    "svm_accuracy = accuracy_score(y_test, svm_pred)\n",
    "nb_accuracy = accuracy_score(y_test, nb_pred)\n",
    "\n",
    "print(\"SVM Accuracy:\", svm_accuracy)\n",
    "print(\"Naive Bayes Accuracy:\", nb_accuracy)\n",
    "\n",
    "print(\"\\nSVM Classification Report:\")\n",
    "print(classification_report(y_test, svm_pred, zero_division=1, target_names=['negative', 'neutral', 'positive']))\n",
    "\n",
    "print(\"\\nNaive Bayes Classification Report:\")\n",
    "print(classification_report(y_test, nb_pred, zero_division=1, target_names=['negative', 'neutral', 'positive']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "284988b4-6d1a-4f7b-8053-d44b00fedce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lexicon-based approach using TextBlob and VADER\n",
    "table_data = [[\"Text\", \"Actual Label\", \"TextBlob Polarity\", \"TextBlob Sentiment\", \n",
    "               \"VADER Compound\", \"VADER Sentiment\"]]\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "for text, actual_label in zip(df['clean_text'], df['Score']):\n",
    "    # TextBlob\n",
    "    blob = TextBlob(text)\n",
    "    tb_polarity = blob.sentiment.polarity\n",
    "\n",
    "    # Determine label based on polarity score from TextBlob\n",
    "    if tb_polarity > 0:\n",
    "        tb_label = 2\n",
    "    elif tb_polarity < 0:\n",
    "        tb_label = 0\n",
    "    else:\n",
    "        tb_label = 1\n",
    "\n",
    "    # VADER\n",
    "    vs = analyzer.polarity_scores(text)\n",
    "    vader_compound = vs['compound']\n",
    "\n",
    "    # Determine label based on compound score from VADER\n",
    "    if vader_compound > 0.05:\n",
    "        vader_label = 2\n",
    "    elif vader_compound < -0.05:\n",
    "        vader_label = 0\n",
    "    else:\n",
    "        vader_label = 1\n",
    "\n",
    "    table_data.append([text, actual_label, tb_polarity, tb_label, vader_compound, vader_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94b9ff40-e390-4b9e-9a53-0c0c78b52e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for TextBlob:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.53      0.34      0.41      2944\n",
      "     neutral       0.08      0.02      0.03      1649\n",
      "    positive       0.82      0.94      0.88     15407\n",
      "\n",
      "    accuracy                           0.78     20000\n",
      "   macro avg       0.47      0.43      0.44     20000\n",
      "weighted avg       0.71      0.78      0.74     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate classification report for TextBlob\n",
    "tb_classification_report = classification_report([label for _, label, _, tb_label, _, _ in table_data[1:]], \n",
    "                                                  [tb_label for _, _, _, tb_label, _, _ in table_data[1:]], \n",
    "                                                  target_names=['negative', 'neutral', 'positive'])\n",
    "\n",
    "# Print classification report for TextBlob\n",
    "print(\"\\nClassification Report for TextBlob:\")\n",
    "print(tb_classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "704991de-43c5-4ed4-86c2-e2575af8243a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for VADER:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.59      0.28      0.38      2944\n",
      "     neutral       0.15      0.04      0.06      1649\n",
      "    positive       0.81      0.96      0.88     15407\n",
      "\n",
      "    accuracy                           0.78     20000\n",
      "   macro avg       0.52      0.43      0.44     20000\n",
      "weighted avg       0.73      0.78      0.74     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate classification report for VADER\n",
    "vader_classification_report = classification_report([label for _, label, _, _, _, vader_label in table_data[1:]], \n",
    "                                                     [vader_label for _, _, _, _, _, vader_label in table_data[1:]], \n",
    "                                                     target_names=['negative', 'neutral', 'positive'])\n",
    "\n",
    "# Print classification report for VADER\n",
    "print(\"\\nClassification Report for VADER:\")\n",
    "print(vader_classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1930fdd1-c154-412c-b62b-173c6483c835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cleaned Text</th>\n",
       "      <th>Actual Label</th>\n",
       "      <th>NB Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2069</th>\n",
       "      <td>beat bisquick doubt expensive fake grocery le ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14914</th>\n",
       "      <td>buying chip chocolate chunk cooky delicious ea...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7634</th>\n",
       "      <td>arrived came enjoy excellently good growing he...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17782</th>\n",
       "      <td>admit bag big buy day delicious end entire eve...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9327</th>\n",
       "      <td>buy delicious different excellent hassle one p...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3660</th>\n",
       "      <td>attributable barely better bitter blueberry bo...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19340</th>\n",
       "      <td>cherry customer enjoyed fl friend love plenty ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>absolutely actually addition although amazing ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>allergic also balance different dog food free ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12194</th>\n",
       "      <td>added adulterant ago almost brand cheap chicke...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Cleaned Text  Actual Label  \\\n",
       "2069   beat bisquick doubt expensive fake grocery le ...             0   \n",
       "14914  buying chip chocolate chunk cooky delicious ea...             2   \n",
       "7634   arrived came enjoy excellently good growing he...             2   \n",
       "17782  admit bag big buy day delicious end entire eve...             2   \n",
       "9327   buy delicious different excellent hassle one p...             2   \n",
       "3660   attributable barely better bitter blueberry bo...             0   \n",
       "19340  cherry customer enjoyed fl friend love plenty ...             2   \n",
       "712    absolutely actually addition although amazing ...             2   \n",
       "95     allergic also balance different dog food free ...             2   \n",
       "12194  added adulterant ago almost brand cheap chicke...             0   \n",
       "\n",
       "       NB Sentiment  \n",
       "2069              2  \n",
       "14914             2  \n",
       "7634              2  \n",
       "17782             2  \n",
       "9327              2  \n",
       "3660              2  \n",
       "19340             2  \n",
       "712               2  \n",
       "95                2  \n",
       "12194             2  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert array of words into regular sentences\n",
    "cleaned_text = [' '.join(words) for words in tfidf_vectorizer.inverse_transform(X_test)]\n",
    "\n",
    "# Save X and predicted labels for Multinomial Naive Bayes model\n",
    "df_nb_result = pd.DataFrame(data={'Cleaned Text': cleaned_text, 'Actual Label': y_test, 'NB Sentiment': nb_pred})\n",
    "df_nb_result.to_csv('X_with_Predicted_Labels_NB.csv', index=False)\n",
    "df_nb_result.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f67ba43-51a6-40ac-895c-944a57d5844e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cleaned Text</th>\n",
       "      <th>Actual Label</th>\n",
       "      <th>SVM Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2069</th>\n",
       "      <td>beat bisquick doubt expensive fake grocery le ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14914</th>\n",
       "      <td>buying chip chocolate chunk cooky delicious ea...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7634</th>\n",
       "      <td>arrived came enjoy excellently good growing he...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17782</th>\n",
       "      <td>admit bag big buy day delicious end entire eve...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9327</th>\n",
       "      <td>buy delicious different excellent hassle one p...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3660</th>\n",
       "      <td>attributable barely better bitter blueberry bo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19340</th>\n",
       "      <td>cherry customer enjoyed fl friend love plenty ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>absolutely actually addition although amazing ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>allergic also balance different dog food free ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12194</th>\n",
       "      <td>added adulterant ago almost brand cheap chicke...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Cleaned Text  Actual Label  \\\n",
       "2069   beat bisquick doubt expensive fake grocery le ...             0   \n",
       "14914  buying chip chocolate chunk cooky delicious ea...             2   \n",
       "7634   arrived came enjoy excellently good growing he...             2   \n",
       "17782  admit bag big buy day delicious end entire eve...             2   \n",
       "9327   buy delicious different excellent hassle one p...             2   \n",
       "3660   attributable barely better bitter blueberry bo...             0   \n",
       "19340  cherry customer enjoyed fl friend love plenty ...             2   \n",
       "712    absolutely actually addition although amazing ...             2   \n",
       "95     allergic also balance different dog food free ...             2   \n",
       "12194  added adulterant ago almost brand cheap chicke...             0   \n",
       "\n",
       "       SVM Sentiment  \n",
       "2069               2  \n",
       "14914              2  \n",
       "7634               2  \n",
       "17782              2  \n",
       "9327               2  \n",
       "3660               0  \n",
       "19340              2  \n",
       "712                2  \n",
       "95                 2  \n",
       "12194              0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert array of words into regular sentences\n",
    "cleaned_text = [' '.join(words) for words in tfidf_vectorizer.inverse_transform(X_test)]\n",
    "\n",
    "# Save X and predicted labels for Support Vector Machine (SVM) model\n",
    "df_svm_result = pd.DataFrame(data={'Cleaned Text': cleaned_text, 'Actual Label': y_test, 'SVM Sentiment': svm_pred})\n",
    "df_svm_result.to_csv('X_with_Predicted_Labels_SVM.csv', index=False)\n",
    "df_svm_result.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ade54326-4873-4982-9e19-6b2916af5af9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Actual Label</th>\n",
       "      <th>TextBlob Polarity</th>\n",
       "      <th>TextBlob Sentiment</th>\n",
       "      <th>VADER Compound</th>\n",
       "      <th>VADER Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bought several vitality canned dog food produc...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9413</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>product arrived labeled jumbo salted peanutsth...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.1027</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>confection around century light pillowy citrus...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.187000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8532</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>looking secret ingredient robitussin believe f...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great taffy great price wide assortment yummy ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9468</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>got wild hair taffy ordered five pound bag taf...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9136</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>saltwater taffy great flavor soft chewy candy ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9463</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>taffy good soft chewy flavor amazing definitel...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9313</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>right mostly sprouting cat eat grass love rota...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>2</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>healthy dog food good digestion also good smal...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.412500</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8176</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Actual Label  \\\n",
       "0  bought several vitality canned dog food produc...             2   \n",
       "1  product arrived labeled jumbo salted peanutsth...             0   \n",
       "2  confection around century light pillowy citrus...             2   \n",
       "3  looking secret ingredient robitussin believe f...             0   \n",
       "4  great taffy great price wide assortment yummy ...             2   \n",
       "5  got wild hair taffy ordered five pound bag taf...             2   \n",
       "6  saltwater taffy great flavor soft chewy candy ...             2   \n",
       "7  taffy good soft chewy flavor amazing definitel...             2   \n",
       "8  right mostly sprouting cat eat grass love rota...             2   \n",
       "9  healthy dog food good digestion also good smal...             2   \n",
       "\n",
       "   TextBlob Polarity  TextBlob Sentiment  VADER Compound  VADER Sentiment  \n",
       "0           0.425000                   2          0.9413                2  \n",
       "1           0.216667                   2         -0.1027                0  \n",
       "2           0.187000                   2          0.8532                2  \n",
       "3           0.150000                   2          0.4404                2  \n",
       "4           0.458333                   2          0.9468                2  \n",
       "5           0.333333                   2          0.9136                2  \n",
       "6           0.210000                   2          0.9463                2  \n",
       "7           0.380000                   2          0.9313                2  \n",
       "8           0.428571                   2          0.6369                2  \n",
       "9           0.412500                   2          0.8176                2  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lexicon-based approach using TextBlob and VADER\n",
    "df_lexicon = pd.DataFrame(table_data[1:], columns=table_data[0])\n",
    "df_lexicon.to_csv('Reviews_Lexicon_Predictions.csv', index=False)\n",
    "df_lexicon.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f4e0d9-ea25-4d2a-9aea-7d940b43d0cd",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "Strengths and weaknesses of the selected models for sentiment classification:\n",
    "\n",
    "=========================================================================================================\n",
    "\n",
    "Support Vector Machine (SVM) model: \n",
    "\n",
    "Strengths:\n",
    "- SVM performs well in high dimensional spaces.\n",
    "- It is effective when the number of dimensions is greater than the number of samples.\n",
    "\n",
    "Weaknesses:\n",
    "- SVM can be computationally expensive, especially with large datasets.\n",
    "\n",
    "=========================================================================================================\n",
    "\n",
    "Multinomial Naive Bayes model:\n",
    "\n",
    "Strengths:\n",
    "- Naive Bayes is simple and fast.\n",
    "- It works well with high-dimensional data like text data.\n",
    "\n",
    "Weaknesses:\n",
    "- Naive Bayes makes a strong assumption about the independence of features, which may not always be true in real-world data.\n",
    "\n",
    "=========================================================================================================\n",
    "\n",
    "TextBlob:\n",
    "\n",
    "Strengths:\n",
    "- TextBlob provides a simple API for common natural language processing (NLP) tasks such as part-of-speech tagging, noun phrase extraction, and sentiment analysis.\n",
    "- It is easy to use and requires minimal preprocessing.\n",
    "\n",
    "Weaknesses:\n",
    "- TextBlob may not perform well on highly specialized or domain-specific text data.\n",
    "- It relies on a pre-trained model and may not capture nuances in sentiment as effectively as custom-trained models.\n",
    "\n",
    "=========================================================================================================\n",
    "\n",
    "VADER (Valence Aware Dictionary and sEntiment Reasoner):\n",
    "\n",
    "Strengths:\n",
    "- VADER is specifically designed for sentiment analysis of social media text.\n",
    "- It provides a score for the sentiment intensity of text, allowing for fine-grained analysis.\n",
    "\n",
    "Weaknesses:\n",
    "- VADER's performance may vary depending on the type of text being analyzed.\n",
    "- It may not perform as well on formal or structured text data compared to informal or unstructured text.\n",
    "\n",
    "=========================================================================================================l or structured text data compared to informal or unstructured text.\r\n",
    "\"\"\" to informal or unstructured text.\r\n",
    "\"\"\"\r\n",
    " informal or unstructured text.\r\n",
    "\"\"\"\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5267ac5b-4ec4-4527-9be4-954e8051ad25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

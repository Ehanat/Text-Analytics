{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6442859-bbd2-4110-853d-918ab2c7b1d1",
   "metadata": {},
   "source": [
    "## Lab Assignment 3 [Text Analytics - CISB5123]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbcd1d1-11d9-4ada-8d80-f2782c126db6",
   "metadata": {},
   "source": [
    "### <span style='background :yellow' > Student Information (Group Members) </span>\n",
    "\n",
    "Member 1\n",
    "\n",
    "**Name     :** Zulfadhli Fakhri bin Johan\n",
    "\n",
    "**ID No    :** SW01081044\n",
    "\n",
    "**Section  :** 02\n",
    "\n",
    "=============================================================\n",
    "\n",
    "Member 2\n",
    "\n",
    "**Name     :** Errenbai Yeerhanati\n",
    "\n",
    "**ID No    :** SW01081538\n",
    "\n",
    "**Section  :** 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43782abe-1732-4f38-b0e1-e7f49a03573c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ZeeF\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ZeeF\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ZeeF\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "# Download NLTK Resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "148e2430-80c0-46df-b687-6c08c00b87c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"news_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cec785be-7b53-4325-aed7-e363c201ccae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I was wondering if anyone out there could enli...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2022-08-02 13:48:37.251043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>I recently posted an article asking what kind ...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2022-08-02 13:48:37.251043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>\\nIt depends on your priorities.  A lot of peo...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2022-08-02 13:48:37.251043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>an excellent automatic can be found in the sub...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2022-08-02 13:48:37.251043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64</td>\n",
       "      <td>: Ford and his automobile.  I need information...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>2022-08-02 13:48:37.251043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  target  \\\n",
       "0           0  I was wondering if anyone out there could enli...       7   \n",
       "1          17  I recently posted an article asking what kind ...       7   \n",
       "2          29  \\nIt depends on your priorities.  A lot of peo...       7   \n",
       "3          56  an excellent automatic can be found in the sub...       7   \n",
       "4          64  : Ford and his automobile.  I need information...       7   \n",
       "\n",
       "       title                        date  \n",
       "0  rec.autos  2022-08-02 13:48:37.251043  \n",
       "1  rec.autos  2022-08-02 13:48:37.251043  \n",
       "2  rec.autos  2022-08-02 13:48:37.251043  \n",
       "3  rec.autos  2022-08-02 13:48:37.251043  \n",
       "4  rec.autos  2022-08-02 13:48:37.251043  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display first 5 rows BEFORE modifying the score\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "067de169-8bb0-4a96-b33a-ad312c999846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I was wondering if anyone out there could enli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I recently posted an article asking what kind ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nIt depends on your priorities.  A lot of peo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>an excellent automatic can be found in the sub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>: Ford and his automobile.  I need information...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  I was wondering if anyone out there could enli...\n",
       "1  I recently posted an article asking what kind ...\n",
       "2  \\nIt depends on your priorities.  A lot of peo...\n",
       "3  an excellent automatic can be found in the sub...\n",
       "4  : Ford and his automobile.  I need information..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use only the 'text' column and remove null values\n",
    "df = df[['text']].dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd63a63d-6b74-4db1-a7fd-965ce9c37fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize stopwords, lemmatizer, and set of stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "import re\n",
    "\n",
    "# Text preprocessing function\n",
    "def preprocess_text(text):\n",
    "    # Remove email addresses\n",
    "    text = re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', '', text)\n",
    "    # Remove strings in the format <...>\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    \n",
    "    tokens = word_tokenize(text.lower())  # Tokenize the text into words and convert to lowercase\n",
    "    tokens = [token for token in tokens if token.isalnum()]  # Filter out non-alphanumeric tokens\n",
    "    tokens = [token for token in tokens if token not in stop_words]  # Remove stopwords from the tokens\n",
    "    tokens = [token for token in tokens if not token.isnumeric()]  # Remove numeric tokens\n",
    "    tokens = [token for token in tokens if len(token) > 1]  # Remove single-letter tokens\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]  # Lemmatize each token\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d67487df-4938-4606-ba11-46f61a4c7e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I was wondering if anyone out there could enli...</td>\n",
       "      <td>[wondering, anyone, could, enlighten, car, saw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I recently posted an article asking what kind ...</td>\n",
       "      <td>[recently, posted, article, asking, kind, rate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nIt depends on your priorities.  A lot of peo...</td>\n",
       "      <td>[depends, priority, lot, people, put, higher, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>an excellent automatic can be found in the sub...</td>\n",
       "      <td>[excellent, automatic, found, subaru, legacy, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>: Ford and his automobile.  I need information...</td>\n",
       "      <td>[ford, automobile, need, information, whether,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  I was wondering if anyone out there could enli...   \n",
       "1  I recently posted an article asking what kind ...   \n",
       "2  \\nIt depends on your priorities.  A lot of peo...   \n",
       "3  an excellent automatic can be found in the sub...   \n",
       "4  : Ford and his automobile.  I need information...   \n",
       "\n",
       "                                      processed_text  \n",
       "0  [wondering, anyone, could, enlighten, car, saw...  \n",
       "1  [recently, posted, article, asking, kind, rate...  \n",
       "2  [depends, priority, lot, people, put, higher, ...  \n",
       "3  [excellent, automatic, found, subaru, legacy, ...  \n",
       "4  [ford, automobile, need, information, whether,...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess the text column\n",
    "df['processed_text'] = df['text'].apply(preprocess_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c4b49bc-f573-4d63-9177-71a0bec53fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Gensim Dictionary object from the preprocessed documents\n",
    "dictionary = corpora.Dictionary(df['processed_text'])\n",
    "\n",
    "# Filter out tokens that appear in less than 15 documents or more than 50% of the documents \n",
    "dictionary.filter_extremes(no_below=15, no_above=0.5) \n",
    "\n",
    "# Convert each preprocessed document into a bag-of-words representation using the dictionary\n",
    "corpus = [dictionary.doc2bow(doc) for doc in df['processed_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84b52959-ddbe-442b-b664-7df1395c201a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train an LDA model on the corpus with 4 topics\n",
    "lda_model = LdaModel(corpus, num_topics=4, id2word=dictionary, passes=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45835765-e07c-4cd2-975c-43ca9e25e447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table with Articles and Topic:\n",
      "                                                 Article  Topic\n",
      "0      I was wondering if anyone out there could enli...      1\n",
      "1      I recently posted an article asking what kind ...      1\n",
      "2      \\nIt depends on your priorities.  A lot of peo...      1\n",
      "3      an excellent automatic can be found in the sub...      1\n",
      "4      : Ford and his automobile.  I need information...      1\n",
      "...                                                  ...    ...\n",
      "11309  Secrecy in Clipper Chip\\n\\nThe serial number o...      2\n",
      "11310  Hi !\\n\\nI am interested in the source of FEAL ...      2\n",
      "11311  The actual algorithm is classified, however, t...      0\n",
      "11312  \\n\\tThis appears to be generic calling upon th...      1\n",
      "11313  \\nProbably keep quiet and take it, lest they g...      1\n",
      "\n",
      "[11096 rows x 2 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Empty list to store dominant topic labels for each document\n",
    "article_labels = []\n",
    "\n",
    "# Iterate over each processed document\n",
    "for i, doc in enumerate(df['processed_text']):\n",
    "    # For each document, convert to bag-of-words representation\n",
    "    bow = dictionary.doc2bow(doc)\n",
    "    # Get list of topic probabilities\n",
    "    topics = lda_model.get_document_topics(bow)\n",
    "    # Determine topic with highest probability\n",
    "    dominant_topic = max(topics, key=lambda x: x[1])[0]\n",
    "    # Append to the list\n",
    "    article_labels.append(dominant_topic)\n",
    "\n",
    "# Create DataFrame\n",
    "df_result = pd.DataFrame({\"Article\": df['text'], \"Topic\": article_labels})\n",
    "\n",
    "# Print the DataFrame\n",
    "print(\"Table with Articles and Topic:\")\n",
    "print(df_result)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89369be9-600f-49e3-9e77-a18922f351ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Terms for Each Topic:\n",
      "Topic 0:\n",
      "- \"key\" (weight: 0.015)\n",
      "- \"encryption\" (weight: 0.008)\n",
      "- \"information\" (weight: 0.007)\n",
      "- \"new\" (weight: 0.007)\n",
      "- \"chip\" (weight: 0.006)\n",
      "- \"program\" (weight: 0.006)\n",
      "- \"system\" (weight: 0.006)\n",
      "- \"file\" (weight: 0.005)\n",
      "- \"use\" (weight: 0.005)\n",
      "- \"clipper\" (weight: 0.005)\n",
      "\n",
      "Topic 1:\n",
      "- \"would\" (weight: 0.014)\n",
      "- \"one\" (weight: 0.010)\n",
      "- \"get\" (weight: 0.010)\n",
      "- \"know\" (weight: 0.009)\n",
      "- \"like\" (weight: 0.009)\n",
      "- \"think\" (weight: 0.008)\n",
      "- \"time\" (weight: 0.007)\n",
      "- \"year\" (weight: 0.007)\n",
      "- \"good\" (weight: 0.007)\n",
      "- \"could\" (weight: 0.006)\n",
      "\n",
      "Topic 2:\n",
      "- \"max\" (weight: 0.022)\n",
      "- \"db\" (weight: 0.010)\n",
      "- \"use\" (weight: 0.009)\n",
      "- \"window\" (weight: 0.009)\n",
      "- \"file\" (weight: 0.008)\n",
      "- \"system\" (weight: 0.008)\n",
      "- \"one\" (weight: 0.007)\n",
      "- \"using\" (weight: 0.006)\n",
      "- \"version\" (weight: 0.006)\n",
      "- \"program\" (weight: 0.005)\n",
      "\n",
      "Topic 3:\n",
      "- \"people\" (weight: 0.011)\n",
      "- \"would\" (weight: 0.009)\n",
      "- \"one\" (weight: 0.009)\n",
      "- \"god\" (weight: 0.006)\n",
      "- \"say\" (weight: 0.005)\n",
      "- \"government\" (weight: 0.005)\n",
      "- \"right\" (weight: 0.005)\n",
      "- \"u\" (weight: 0.005)\n",
      "- \"think\" (weight: 0.004)\n",
      "- \"state\" (weight: 0.004)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the top terms for each topic with weight\n",
    "print(\"Top Terms for Each Topic:\")\n",
    "for idx, topic in lda_model.print_topics():\n",
    "    print(f\"Topic {idx}:\")\n",
    "    terms = [term.strip() for term in topic.split(\"+\")]\n",
    "    for term in terms:\n",
    "        weight, word = term.split(\"*\")\n",
    "        print(f\"- {word.strip()} (weight: {weight.strip()})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "403c632c-3027-4885-8ba8-c43076739ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the coherence score for the LDA model\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=df['processed_text'], dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59a61745-bca1-48df-b3b2-26bcd26dc7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic Coherence Score (C_V): 0.5707\n"
     ]
    }
   ],
   "source": [
    "# Print the coherence score\n",
    "print(f'Topic Coherence Score (C_V): {coherence_lda:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7ca139-8f96-44c5-ace5-e84633bd1027",
   "metadata": {},
   "source": [
    "# Topic Modeling with LDA\n",
    "Number of Topics\n",
    "- The LDA model was trained to identify 4 topics from the dataset. Each document was then assigned a dominant topic based on the highest probability of topic representation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf95550-940d-45ee-8b60-38471f7b4551",
   "metadata": {},
   "source": [
    "# Interpretation of the Top Terms for Each Topic\n",
    "Top Terms for Each Topic\r\n",
    "- Topic 0: Primarily relates to technical and encryption-related content, with terms like \"key,\" \"encryption,\" \"information,\" and \"chip.\"\n",
    "- Topic 1: Contains general conversational terms, suggesting topics related to opinions, discussions, or inquiries, with words like \"would,\" \"one,\" \"get,\" and \"know.\"\n",
    "- Topic 2: Appears to be focused on software or technical instructions, featuring words like \"max,\" \"db,\" \"use,\" \"window,\" and \"file.\"\r\n",
    "- Topic 3: Seems to cover social or political discussions, indicated by terms like \"people,\" \"god,\" \"government,\" \"right,\" and \"state.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f21e38-15ce-4a13-9a19-fcdea52e6f46",
   "metadata": {},
   "source": [
    "# Interpretation of the Coherence Score\n",
    "Topic Coherence Score (C_V)\n",
    "- The coherence score of 0.5707 suggests that the topics identified by the LDA model are reasonably coherent and interpretable. This indicates that the model has been able to identify distinct and meaningful topics from the dataset, though there is still room for improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868cb702-2342-4fb3-8dc3-259c7911eb35",
   "metadata": {},
   "source": [
    "# Summary\n",
    "LDA Model\n",
    "- Successfully identified 4 distinct topics in the dataset, with each document being assigned a dominant topic based on its content.\r\n",
    "\n",
    "Coherence Score\n",
    "- The coherence score provides a quantitative measure of the quality of the topics, indicating that the topics are fairly well-defined and interpretable.\n",
    "- The coherence score helps in evaluating the effectiveness of the topic modeling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5514f4e9-bcb8-42a2-a877-e9f041eb16db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
